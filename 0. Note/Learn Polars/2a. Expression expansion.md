---
tags:
  - note
Project:
  - "[[Lean Polars]]"
Status: In progress
---
These are a great way to avoid repeating yourself by having calculations that can be easily expanded to cover multiple different columns without re-defining the same expression for each column. 
## Data for section 
```rust
use polars::prelude::*;

// Data as of 14th October 2024, ~3pm UTC
let df = df!(
    "ticker" => ["AAPL", "NVDA", "MSFT", "GOOG", "AMZN"],
    "company_name" => ["Apple", "NVIDIA", "Microsoft", "Alphabet (Google)", "Amazon"],
    "price" => [229.9, 138.93, 420.56, 166.41, 188.4],
    "day_high" => [231.31, 139.6, 424.04, 167.62, 189.83],
    "day_low" => [228.6, 136.3, 417.52, 164.78, 188.44],
    "year_high" => [237.23, 140.76, 468.35, 193.31, 201.2],
    "year_low" => [164.08, 39.23, 324.39, 121.46, 118.35],
)?;

println!("{}", df);
```
## col
This is a function that is used to grab specific columns from a `DataFrame` the simplest way to make use of this with expression expansion is to provide multiple columns to the function (in rust you will need to use `cols`).
### Example
```rust
let eur_usd_rate = 1.09; // As of 14th October 2024

let result = df
    .clone()
    .lazy()
    .with_column(
        (cols(["price", "day_high", "day_low", "year_high", "year_low"]) / lit(eur_usd_rate))
            .round(2),
    )
    .collect()?;
println!("{}", result);
```
This applies the `eur_usd` conversion to all the price columns in our `DataFrame`.
### regex col
You can provide a regex to fetch column names based on patterns rather than explicitly naming the columns. This is especially useful if you are creating columns using suffixes or prefix aliases. 
This however requires the `regex` feature flag.

#### Example
```rust
let result = df
    .clone()
    .lazy()
    .select([cols(["ticker", "^.*_high$", "^.*_low$"])])
    .collect()?;
println!("{}", result);
```
## dtype_col
This is briefly mentioned in [[2. Expressions and contexts#Expressions|expressions]] where we show that you can apply expressions in contexts using specific data types instead of explicit column names. 
In rust I can envision this being especially useful as you can make use of enum variants and structs to apply things to new type patterns.

### Example
```rust
let result = df
    .clone()
    .lazy()
    .with_column((dtype_col(&DataType::Float64) / lit(eur_usd_rate)).round(2))
    // Alternative with 2 datatypes
	// .with_column(
    //    (dtype_cols([DataType::Float32, DataType::Float64]) / lit(eu r_usd_rate)).round(2),
    )
    .collect()?;
println!("{}", result);
```
This applies the `eur_usd` conversion to all columns of the `DataFrame` that are of the type f64.
## all
Well if I want to do something to all columns I just need to supply all() in place of any of the above. 
## exclude
This is applied to all `all().exclude([...])`, this takes data types, column names or regexes as arguments and removes any column that matches those patterns from the all() call. 
This can however also be applied to `col` calls. 
## Column renaming
By default all expressions evaluated on a `DataFrame` will name the resulting column the same name as the original column. This can cause errors when the same name is provided for multiple columns, which can occur very easily. 
### Example
```rust
let gbp_usd_rate = 1.31; // As of 14th October 2024

let result = df
    .clone()
    .lazy()
    .select([
        col("price") / lit(gbp_usd_rate),
        col("price") / lit(eur_usd_rate),
    ])
    .collect();
match result {
    Ok(df) => println!("{}", df),
    Err(e) => println!("{}", e),
};
```
As you can see we now have 2 price columns.
### alias
To address the above problem we can simply alias each column individually.
```rust
let _result = df
    .clone()
    .lazy()
    .select([
        (col("price") / lit(gbp_usd_rate)).alias("price (GBP)"),
        (col("price") / lit(eur_usd_rate)).alias("price (EUR)"),
    ])
    .collect()?;
```
We no longer get the error as we have given the price columns new names.
But this could be tedious.
### Prefixing and suffixing
To address the above we use suffixing and prefixing to adjust names or all columns that an expression is expanded against.
```rust
let result = df
    .clone()
    .lazy()
    .select([
        (col("^year_.*$") / lit(eur_usd_rate))
            .name()
            .prefix("in_eur_"),
        (cols(["day_high", "day_low"]) / lit(gbp_usd_rate))
            .name()
            .suffix("_gbp"),
    ])
    .collect()?;
println!("{}", result);
```
Now all out columns have distinct names using prefixes and suffixes. This however only works when expanding expressions against different columns or applying different expansions with different prefixes/suffixes against the same column.

### Dynamic name replacement
Here we can apply a more programmatic way of creating names. 
using the `name` function this exposes another function `map` this takes a function/closure/callable that creates the new name. 

#### Example
```rust
// There is also `name().to_uppercase()`, so this usage of `map` is moot.
let result = df
    .clone()
    .lazy()
    .select([all()
        .name()
        .map(|name| Ok(PlSmallStr::from_string(name.to_ascii_uppercase())))])
    .collect()?;
println!("{}", result);
```
## Programmatically generating expressions
Simply put, prefer creating vectors of expressions over applying expressions in a for loop and applying them to a context within that for loop. 
### Bad example
```rust
let mut result = df.clone().lazy();
for tp in ["day", "year"] {
    let high = format!("{}_high", tp);
    let low = format!("{}_low", tp);
    let aliased = format!("{}_amplitude", tp);
    result = result.with_column((col(high) - col(low)).alias(aliased))
}
let result = result.collect()?;
println!("{}", result);
```
Here we are applying the expressions one at a time in a for loop and adding the columns one at time using the with_column context. I assume this is both slower and less "idiomatic".
### Good example
```rust
let mut exprs: Vec<Expr> = vec![];
for tp in ["day", "year"] {
    let high = format!("{}_high", tp);
    let low = format!("{}_low", tp);
    let aliased = format!("{}_amplitude", tp);
    exprs.push((col(high) - col(low)).alias(aliased))
}
let result = df.clone().lazy().with_columns(exprs).collect()?;
println!("{}", result);
```
Here we are creating our expressions, keeping them in a vector and then applying them in a single context thus doing everything in one go. Once again I assume this is more efficient and more idiomatic.
This performance comes from query optimisation and parallelism of computations. 
## More flexible column selection
*Python only*
```python
import polars.selectors as cs

result = df.select(cs.string() | cs.ends_with("_high"))
print(result)
```
I suppose this kind of does the same thing as using a regex, but a simpler interface?
Ah this example is more informative. 
```python
result = df.select(cs.contains("_") - cs.string())
print(result)
```
Here we select all columns that names contains an \_ and then we remove all columns that are String type.
